# Analyzing the Effectiveness of Pruning, Quantization & Distillation for Next-Generation LLM Compression

![Summarized Results](./final-results.png)

## Introduction

[LLMCBench: Benchmarking Large Language Model Compression for Efficient Deployment [arXiv]](https://arxiv.org/abs/2410.21352)

 The **L**arge **L**anguage **M**odel **C**ompression **Bench**mark (LLMCBench) is a rigorously designed benchmark with an in-depth analysis for LLM compression algorithms. 


 **IMPORTANT**: The main functionality of our repo lie in run.sh


## Usage

This repo contains codes for testing MMLU, MNLI, QNLI, Wikitext2, advGLUE, TruthfulQA datasets and FLOPs.
